{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "from keras.utils import *\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of cores to 16\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=16, \n",
    "                                                   inter_op_parallelism_threads=16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', (5008,)), ('G', (5008, 57876, 4)), ('V', (57876, 4))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load genetic data\n",
    "chr1kg = np.load('/home/magu/deepmix/data/ALL_DNA_dataset/chr1_1kg_X.npz')\n",
    "\n",
    "# S are samples, G are genotypes, V are variants\n",
    "[(i,chr1kg[i].shape) for i in chr1kg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HG00096_S1', 'HG00097_S1', 'HG00099_S1', 'HG00100_S1',\n",
       "       'HG00101_S1'], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=chr1kg['S'].astype(str)\n",
    "S[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['1', '723307', 'C', 'G'],\n",
       "       ['1', '727841', 'G', 'A']], dtype='<U225')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V=chr1kg['V'].astype(str)\n",
    "V[:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5008, 57876, 4)\n"
     ]
    }
   ],
   "source": [
    "G=chr1kg['G'].astype(bool)\n",
    "print(G.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free up memory\n",
    "chr1kg=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ancestry labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Biosample ID</th>\n",
       "      <th>Population code</th>\n",
       "      <th>Population name</th>\n",
       "      <th>Superpopulation code</th>\n",
       "      <th>Superpopulation name</th>\n",
       "      <th>Population elastic ID</th>\n",
       "      <th>Data collections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>HGDP00982</td>\n",
       "      <td>male</td>\n",
       "      <td>SAMEA3302833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mbuti</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Africa (SGDP)</td>\n",
       "      <td>MbutiSGDP</td>\n",
       "      <td>Simons Genome Diversity Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>Dus22</td>\n",
       "      <td>female</td>\n",
       "      <td>SAMEA3302688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dusun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oceania (SGDP)</td>\n",
       "      <td>DusunSGDP</td>\n",
       "      <td>Simons Genome Diversity Project</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>NA13607</td>\n",
       "      <td>male</td>\n",
       "      <td>SAMEA3302722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>East Asia (SGDP)</td>\n",
       "      <td>AmiSGDP</td>\n",
       "      <td>Simons Genome Diversity Project</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sample name     Sex  Biosample ID Population code Population name  \\\n",
       "4969   HGDP00982    male  SAMEA3302833             NaN           Mbuti   \n",
       "4970       Dus22  female  SAMEA3302688             NaN           Dusun   \n",
       "4971     NA13607    male  SAMEA3302722             NaN             Ami   \n",
       "\n",
       "     Superpopulation code Superpopulation name Population elastic ID  \\\n",
       "4969                  NaN        Africa (SGDP)             MbutiSGDP   \n",
       "4970                  NaN       Oceania (SGDP)             DusunSGDP   \n",
       "4971                  NaN     East Asia (SGDP)               AmiSGDP   \n",
       "\n",
       "                     Data collections  \n",
       "4969  Simons Genome Diversity Project  \n",
       "4970  Simons Genome Diversity Project  \n",
       "4971  Simons Genome Diversity Project  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_info=pd.read_csv('/home/jsokol/Data/igsr_samples.tsv', sep=\"\\t\")\n",
    "sample_info.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4019, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## REMOVE AMERICANS + ADMIXED POPS\n",
    "pops_to_remove=['ASW','MXL','CEU','PUR','PEL','CLM','ACB'] # +['GIH','ITU','STU']\n",
    "samples=sample_info[~sample_info['Population code'].isin(pops_to_remove)]\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, {'EUR': 0, 'EAS': 1, 'SAS': 2, 'AFR': 3})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=samples[\"Superpopulation code\"].dropna().unique().tolist()\n",
    "labels=dict(zip(labels, range(len(labels))))\n",
    "k=len(labels)\n",
    "(k, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3802, 57876)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S=[i for i in S if i[:-3] in samples['Sample name'].values]\n",
    "S_pop=[str(samples.loc[samples['Sample name']==i[:-3], \"Superpopulation code\"].values[0]) for i in S]\n",
    "Y=np.array([[labels[pop] for _ in range(G.shape[1])] for pop in S_pop])\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[np.array([1,345,2222]),:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nope='''Y2=[]\n",
    "for i in range(Y.shape[0]): # individuals\n",
    "    Y2.append([])\n",
    "    for j in range(Y.shape[1]): # sites\n",
    "        Y2[-1].append(np.zeros(k))\n",
    "        Y2[-1][-1][labels[Y[i,j]]]=1\n",
    "Y=np.array(Y2)\n",
    "Y2=[]\n",
    "print(Y.shape)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "also_nope='''for pop,i in labels.items():\n",
    "    Y[np.where(Y==pop)]=i\n",
    "Y=np.expand_dims(Y, 2)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('/home/magu/deepmix/data/ALL_DNA_dataset/chr1_1kg_X_int.train.txt', header=None).iloc[:,0].values\n",
    "dev=pd.read_csv('/home/magu/deepmix/data/ALL_DNA_dataset/chr1_1kg_X_int.dev.txt', header=None).iloc[:,0].values\n",
    "test=pd.read_csv('/home/magu/deepmix/data/ALL_DNA_dataset/chr1_1kg_X_int.test.txt', header=None).iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3510,), (152,), (140,)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ix=np.array([i for i,x in enumerate(S) if x in train and x[:-3] in list(samples['Sample name'])])\n",
    "dev_ix=np.array([i for i,x in enumerate(S) if x in dev and x[:-3] in list(samples['Sample name'])])\n",
    "test_ix=np.array([i for i,x in enumerate(S) if x in test and x[:-3] in list(samples['Sample name'])])\n",
    "[train_ix.shape, dev_ix.shape, test_ix.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3510, 57876, 4), (3510, 57876)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X=G[train_ix,:,:]\n",
    "train_Y=Y[train_ix,:]\n",
    "[train_X.shape, train_Y.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(152, 57876, 4), (152, 57876)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_X=G[dev_ix,:,:]\n",
    "dev_Y=Y[dev_ix,:]\n",
    "[dev_X.shape, dev_Y.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(140, 57876, 4), (140, 57876)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X=G[test_ix,:,:]\n",
    "test_Y=Y[test_ix,:]\n",
    "[test_X.shape, test_Y.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augment training set with admixed individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(10530, 57876, 4), (10530, 57876)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take number of ancestors as Pois(2.86 * generation_time), over 1-10 (maxgen) generations\n",
    "n_fake=4*train_X.shape[0]\n",
    "maxgen=2\n",
    "n_splits=2+np.hstack([ss.poisson.rvs(2.86*gen, size=n_fake//maxgen) for gen in range(1,maxgen)])\n",
    "\n",
    "# new individuals\n",
    "new_X=[]\n",
    "new_Y=[]\n",
    "for j in n_splits:\n",
    "    if j==0:\n",
    "        ind=np.random.choice(np.arange(train_X.shape[0]), size=1)\n",
    "        new_X.append(list(train_X[ind,:,:]))\n",
    "        new_Y.append(list(train_Y[ind,:]))\n",
    "    # sample breakpoints uniformly\n",
    "    breaks=np.sort(V.shape[0] * ss.beta.rvs(a=1, b=1, size=j)).astype(int)\n",
    "    # pick founders uniformly at random without replacement and stitch their labels together\n",
    "    founds=np.random.choice(np.arange(train_X.shape[0]), size=j+1, replace=False)\n",
    "    # assemble genome and labels\n",
    "    new_x,new_y = [],[]\n",
    "    new_x.append(train_X[founds[0],:breaks[0],:])\n",
    "    new_y.append(train_Y[founds[0],:breaks[0]])\n",
    "    for i,found in enumerate(founds[1:-1]):\n",
    "        new_x.append(train_X[found, breaks[i]:breaks[i+1],:])\n",
    "        new_y.append(train_Y[found, breaks[i]:breaks[i+1]])\n",
    "    new_x.append(train_X[founds[-1], breaks[-1]:,:])\n",
    "    new_y.append(train_Y[founds[-1], breaks[-1]:])\n",
    "    new_X.append(np.vstack(new_x))\n",
    "    new_Y.append(np.hstack(new_y))\n",
    "train_X=np.vstack((train_X, new_X))\n",
    "train_Y=np.vstack((train_Y, new_Y))\n",
    "[train_X.shape, train_Y.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9a202d2d68>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(train_Y[-40:,:2048].astype(int), aspect='auto', cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_u(input_shape):\n",
    "    \"\"\"\n",
    "    input_shape: The height, width and channels as a tuple.  \n",
    "        Note that this does not include the 'batch' as a dimension.\n",
    "        If you have a batch like 'X_train', \n",
    "        then you can provide the input_shape using\n",
    "        X_train.shape[1:]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(shape=input_shape)\n",
    "\n",
    "    # First convolutional block\n",
    "    #conv0 = Conv1D(filters=input_shape[1], kernel_size=1, padding='same')(X_input)\n",
    "    #drop1 = Dropout(0.33)(conv0)\n",
    "    ks=8\n",
    "    conv1 = Conv1D(filters=64, kernel_size=ks, padding = 'same')(X_input)\n",
    "    bn1 = BatchNormalization(axis = -1)(conv1)\n",
    "    conv1 = Activation('relu')(bn1)\n",
    "    pool1 = MaxPooling1D(2)(conv1)\n",
    "\n",
    "    # Second convolutional block with maxpool\n",
    "    conv2 = Conv1D(filters=128, kernel_size=ks, padding = 'same', name = 'conv1')(bn1)\n",
    "    bn2 = BatchNormalization(axis = -1)(conv2)\n",
    "    conv2 = Activation('relu')(bn2)\n",
    "    pool2 = MaxPooling1D(2)(conv2)\n",
    "\n",
    "    # Third convolutional block with maxpool\n",
    "    conv3 = Conv1D(filters=512, kernel_size=ks, padding = 'same')(pool2)\n",
    "    bn3 = BatchNormalization(axis = -1)(conv3)\n",
    "    conv3 = Activation('relu')(bn3)    \n",
    "    pool3 = MaxPooling1D(2)(conv3)\n",
    "        \n",
    "    # Now you just go back up\n",
    "    conv4 = Conv1D(filters=512, kernel_size=ks, padding='same')(pool3) # (UpSampling1D(size = 2)(pool3))\n",
    "    conv4 = Activation('relu')(conv4)\n",
    "    merge4= concatenate([conv4, pool3], axis=1)\n",
    "    conv5 = Conv1D(filters=512, kernel_size=ks, padding='same')(merge4)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "\n",
    "    conv6 = Conv1D(filters=128, kernel_size=ks, padding = 'same')(conv5) # (UpSampling1D(size = 2)(conv5))\n",
    "    bn6 = BatchNormalization(axis = -1)(conv6)\n",
    "    conv6 = Activation('relu')(bn6)\n",
    "    merge6= concatenate([conv6, pool2], axis=1)\n",
    "    conv7 = Conv1D(filters=64, kernel_size=ks, padding = 'same')(merge6)\n",
    "    conv7 = Activation('relu')(conv7)\n",
    "    Yhat = Conv1D(k, kernel_size=1, activation = 'softmax')(conv7)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = Yhat, name='model2b')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_shape):\n",
    "    # ref: https://github.com/zhixuhao/unet\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    # hopefully a big feature extractor\n",
    "    '''conv1={}\n",
    "    max_pow=9\n",
    "    for f in [2**i for i in range(1, max_pow)]:\n",
    "        conv1[f] = Conv1D(filters=64, kernel_size=f, activation='tanh', padding='same')(X_input)\n",
    "    conv1 = concatenate(list(conv1.values()), axis=-1)'''\n",
    "    X = Conv1D(filters=64, kernel_size=32, strides=16, padding='same')(X_input)\n",
    "    X = BatchNormalization(axis = -1)(X)\n",
    "    X = Activation('tanh')(X)\n",
    "    \n",
    "    X = Conv1D(filters=64, kernel_size=16, strides=4, activation='tanh', padding='same')(X)\n",
    "    \n",
    "    # do something with those features\n",
    "    rfk=64 # local predictor size\n",
    "    rfn=1 # padding\n",
    "    X = LocallyConnected1D(filters=k, kernel_size=rfk, activation = 'tanh', padding = 'valid', \n",
    "                           strides=rfn, kernel_initializer = 'he_normal')(ZeroPadding1D(padding=(rfk//2,rfk//2 - 1))(X))\n",
    "    \"\"\"conv3 = Conv1D(filters=64, kernel_size=16, activation = 'tanh', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv2)\n",
    "    conv4 = Conv1D(filters=64, kernel_size=16, activation = 'tanh', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv3)\n",
    "    conv5 = Conv1D(filters=64, kernel_size=16, activation = 'tanh', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv4)\n",
    "    conv6 = Conv1D(filters=64, kernel_size=16, activation = 'tanh', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv5)\"\"\"\n",
    "    X = Conv1D(32, 64, padding='same', activation='tanh')(UpSampling1D(16*4*rfn)(X))\n",
    "    X = Conv1D(8, 8, padding='same', activation='tanh')(X)\n",
    "    X = Conv1D(k, 1, activation='softmax')(X)\n",
    "    #X = Dense(64, activation='tanh')(UpSampling1D(16)(X))\n",
    "    #X = Dense(64, activation='tanh')(X)\n",
    "    \n",
    "    # output layer, sure why not, idk\n",
    "    #conv3 = Conv1D(filters=k, kernel_size=1, activation='softmax', padding='same', \n",
    "    #               kernel_initializer = 'he_normal')(conv2)\n",
    "    # X = Dense(k, activation='softmax')(X)\n",
    "\n",
    "    return Model(inputs=X_input, outputs=X, name='yolo')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, ks=4):\n",
    "    # ref: https://github.com/zhixuhao/unet\n",
    "    X_input = Input(shape=input_shape)\n",
    "\n",
    "    fsh=4 # fudge factor to reduce number of network parameters\n",
    "    conv1 = Conv1D(filters=32, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(X_input)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "    conv2 = Conv1D(filters=128//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv1D(filters=128//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    conv3 = Conv1D(filters=256//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv1D(filters=256//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "    conv4 = Conv1D(filters=512//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv1D(filters=512//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(conv4)\n",
    "        \n",
    "    conv5 = Conv1D(filters=1024//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv1D(filters=1024//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv5)\n",
    "\n",
    "    up6 = Conv1D(filters=512//fsh, kernel_size=ks//2, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv5))\n",
    "    merge6 = concatenate([conv4,up6], axis = -1)\n",
    "    conv6 = Conv1D(filters=512//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv1D(filters=512//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv1D(filters=256//fsh, kernel_size=ks//2, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = -1)\n",
    "    conv7 = Conv1D(filters=256//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv1D(filters=256//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv1D(filters=128//fsh, kernel_size=ks//2, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = -1)\n",
    "    conv8 = Conv1D(filters=128//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv1D(filters=128//fsh, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv1D(filters=64, kernel_size=ks//2, activation = 'relu', padding = 'same', \n",
    "                 kernel_initializer = 'he_normal')(UpSampling1D(size = 2)(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = -1)\n",
    "    conv9 = Conv1D(filters=64, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv1D(filters=64, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv1D(filters=2*4, kernel_size=ks, activation = 'relu', padding = 'same', \n",
    "                   kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv1D(filters=4, kernel_size=1, activation = 'softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = conv10, name='model3')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(input_shape):\n",
    "    X_input = Input(shape=input_shape)\n",
    "    \n",
    "    rfw=512\n",
    "    X = LocallyConnected1D(filters=4*k, kernel_size=rfw, strides=rfw, activation='relu',\n",
    "                           kernel_initializer='glorot_normal')(X_input)\n",
    "    X = Conv1D(filters=32, kernel_size=k, padding='same', activation='tanh', kernel_initializer='he_normal')(X)\n",
    "    X = Conv1D(filters=32, kernel_size=k, padding='same', activation='tanh', kernel_initializer='he_normal')(X)\n",
    "    X = Conv1D(filters=32, kernel_size=k, padding='same', activation='tanh', kernel_initializer='he_normal')(X)\n",
    "    X = Conv1D(filters=32, kernel_size=k, padding='same', activation='tanh', kernel_initializer='he_normal')(X)\n",
    "    # X = Conv1D(filters=64, kernel_size=64, strides=4, padding='same', activation='tanh')(X)\n",
    "    # X = Dense(64)(X)\n",
    "    # X = Conv1D(filters=4, kernel_size=16, padding='same', activation='softmax')(X)\n",
    "    X = UpSampling1D(rfw)(X)\n",
    "    # X = Conv1D(filters=k*k, kernel_size=2*rfw, activation='tanh', padding='same', initialization='he_normal')(X)\n",
    "    X = Conv1D(filters=k*k, kernel_size=32, activation='tanh', padding='same', kernel_initializer='he_normal')(X)\n",
    "    X = Conv1D(filters=k, kernel_size=1, activation='softmax', padding='same')(X)\n",
    "    \n",
    "    return Model(inputs=X_input, outputs=X, name='windowCNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 8192, 4)           0         \n",
      "_________________________________________________________________\n",
      "locally_connected1d_19 (Loca (None, 16, 16)            524544    \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 16, 32)            2080      \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 16, 32)            4128      \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 16, 32)            4128      \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 16, 32)            4128      \n",
      "_________________________________________________________________\n",
      "up_sampling1d_27 (UpSampling (None, 8192, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 8192, 16)          16400     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 8192, 4)           68        \n",
      "=================================================================\n",
      "Total params: 555,476\n",
      "Trainable params: 555,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "nc,nv= (2048,8192) #train_X.shape[:2]\n",
    "# nv-=4 # as a freaking edge case\n",
    "keep=np.random.choice(np.arange(train_ix.shape[0]), replace=False, size=nc)\n",
    "model = window(train_X[keep,:nv].shape[1:])\n",
    "# compile model\n",
    "model.compile(optimizer=Adam(lr=1e-3), loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2048 samples, validate on 152 samples\n",
      "Epoch 1/128\n",
      "2048/2048 [==============================] - 57s 28ms/step - loss: 1.4075 - sparse_categorical_accuracy: 0.2522 - val_loss: 1.4083 - val_sparse_categorical_accuracy: 0.2473\n",
      "Epoch 2/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 1.3826 - sparse_categorical_accuracy: 0.2797 - val_loss: 1.3978 - val_sparse_categorical_accuracy: 0.2747\n",
      "Epoch 3/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 1.3599 - sparse_categorical_accuracy: 0.3106 - val_loss: 1.3893 - val_sparse_categorical_accuracy: 0.2908\n",
      "Epoch 4/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 1.3406 - sparse_categorical_accuracy: 0.3226 - val_loss: 1.3864 - val_sparse_categorical_accuracy: 0.3005\n",
      "Epoch 5/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 1.3097 - sparse_categorical_accuracy: 0.3440 - val_loss: 1.4923 - val_sparse_categorical_accuracy: 0.3014\n",
      "Epoch 6/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 1.2555 - sparse_categorical_accuracy: 0.3840 - val_loss: 1.4757 - val_sparse_categorical_accuracy: 0.2452\n",
      "Epoch 7/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 1.2132 - sparse_categorical_accuracy: 0.4136 - val_loss: 1.4958 - val_sparse_categorical_accuracy: 0.2648\n",
      "Epoch 8/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 1.1575 - sparse_categorical_accuracy: 0.4458 - val_loss: 1.5656 - val_sparse_categorical_accuracy: 0.2983\n",
      "Epoch 9/128\n",
      "2048/2048 [==============================] - 56s 27ms/step - loss: 1.1058 - sparse_categorical_accuracy: 0.4794 - val_loss: 1.5400 - val_sparse_categorical_accuracy: 0.2937\n",
      "Epoch 10/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 1.0444 - sparse_categorical_accuracy: 0.5118 - val_loss: 1.5655 - val_sparse_categorical_accuracy: 0.3340\n",
      "Epoch 11/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.9297 - sparse_categorical_accuracy: 0.5826 - val_loss: 1.7912 - val_sparse_categorical_accuracy: 0.2750\n",
      "Epoch 12/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.8959 - sparse_categorical_accuracy: 0.5882 - val_loss: 1.7820 - val_sparse_categorical_accuracy: 0.3208\n",
      "Epoch 13/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.7865 - sparse_categorical_accuracy: 0.6552 - val_loss: 1.8974 - val_sparse_categorical_accuracy: 0.3119\n",
      "Epoch 14/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.8150 - sparse_categorical_accuracy: 0.6561 - val_loss: 1.8378 - val_sparse_categorical_accuracy: 0.2958\n",
      "Epoch 15/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.7229 - sparse_categorical_accuracy: 0.7032 - val_loss: 1.9723 - val_sparse_categorical_accuracy: 0.3064\n",
      "Epoch 16/128\n",
      "2048/2048 [==============================] - 56s 27ms/step - loss: 0.7018 - sparse_categorical_accuracy: 0.6942 - val_loss: 1.9385 - val_sparse_categorical_accuracy: 0.3267\n",
      "Epoch 17/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.6085 - sparse_categorical_accuracy: 0.7524 - val_loss: 2.1040 - val_sparse_categorical_accuracy: 0.3244\n",
      "Epoch 18/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.5114 - sparse_categorical_accuracy: 0.7997 - val_loss: 2.3151 - val_sparse_categorical_accuracy: 0.3178\n",
      "Epoch 19/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7494 - val_loss: 2.2993 - val_sparse_categorical_accuracy: 0.3315\n",
      "Epoch 20/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.4386 - sparse_categorical_accuracy: 0.8292 - val_loss: 2.3623 - val_sparse_categorical_accuracy: 0.3136\n",
      "Epoch 21/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.4104 - sparse_categorical_accuracy: 0.8438 - val_loss: 2.4824 - val_sparse_categorical_accuracy: 0.3239\n",
      "Epoch 22/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.3521 - sparse_categorical_accuracy: 0.8684 - val_loss: 2.6037 - val_sparse_categorical_accuracy: 0.3266\n",
      "Epoch 23/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.3969 - sparse_categorical_accuracy: 0.8481 - val_loss: 2.6039 - val_sparse_categorical_accuracy: 0.3147\n",
      "Epoch 24/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.3185 - sparse_categorical_accuracy: 0.8800 - val_loss: 2.6685 - val_sparse_categorical_accuracy: 0.3138\n",
      "Epoch 25/128\n",
      "2048/2048 [==============================] - 51s 25ms/step - loss: 0.2546 - sparse_categorical_accuracy: 0.9086 - val_loss: 2.7901 - val_sparse_categorical_accuracy: 0.3225\n",
      "Epoch 26/128\n",
      "2048/2048 [==============================] - 52s 25ms/step - loss: 0.2789 - sparse_categorical_accuracy: 0.8929 - val_loss: 2.9315 - val_sparse_categorical_accuracy: 0.3179\n",
      "Epoch 27/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.2401 - sparse_categorical_accuracy: 0.9128 - val_loss: 3.0254 - val_sparse_categorical_accuracy: 0.3302\n",
      "Epoch 28/128\n",
      "2048/2048 [==============================] - 51s 25ms/step - loss: 0.2610 - sparse_categorical_accuracy: 0.9041 - val_loss: 2.9253 - val_sparse_categorical_accuracy: 0.3155\n",
      "Epoch 29/128\n",
      "2048/2048 [==============================] - 50s 24ms/step - loss: 0.1937 - sparse_categorical_accuracy: 0.9311 - val_loss: 3.1099 - val_sparse_categorical_accuracy: 0.3200\n",
      "Epoch 30/128\n",
      "2048/2048 [==============================] - 52s 25ms/step - loss: 0.2024 - sparse_categorical_accuracy: 0.9292 - val_loss: 3.2686 - val_sparse_categorical_accuracy: 0.3000\n",
      "Epoch 31/128\n",
      "2048/2048 [==============================] - 51s 25ms/step - loss: 0.1938 - sparse_categorical_accuracy: 0.9302 - val_loss: 3.2962 - val_sparse_categorical_accuracy: 0.3075\n",
      "Epoch 32/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.1645 - sparse_categorical_accuracy: 0.9429 - val_loss: 3.3852 - val_sparse_categorical_accuracy: 0.3121\n",
      "Epoch 33/128\n",
      "2048/2048 [==============================] - 56s 28ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9469 - val_loss: 3.4957 - val_sparse_categorical_accuracy: 0.3048\n",
      "Epoch 34/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9562 - val_loss: 3.3844 - val_sparse_categorical_accuracy: 0.3086\n",
      "Epoch 35/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.1468 - sparse_categorical_accuracy: 0.9475 - val_loss: 3.5025 - val_sparse_categorical_accuracy: 0.3195\n",
      "Epoch 36/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.0910 - sparse_categorical_accuracy: 0.9700 - val_loss: 3.4991 - val_sparse_categorical_accuracy: 0.3254\n",
      "Epoch 37/128\n",
      "2048/2048 [==============================] - 50s 24ms/step - loss: 0.1577 - sparse_categorical_accuracy: 0.9446 - val_loss: 3.4822 - val_sparse_categorical_accuracy: 0.3097\n",
      "Epoch 38/128\n",
      "2048/2048 [==============================] - 52s 25ms/step - loss: 0.2387 - sparse_categorical_accuracy: 0.9164 - val_loss: 3.0630 - val_sparse_categorical_accuracy: 0.3158\n",
      "Epoch 39/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9476 - val_loss: 3.5654 - val_sparse_categorical_accuracy: 0.3222\n",
      "Epoch 40/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.0887 - sparse_categorical_accuracy: 0.9705 - val_loss: 3.8050 - val_sparse_categorical_accuracy: 0.3065\n",
      "Epoch 41/128\n",
      "2048/2048 [==============================] - 54s 27ms/step - loss: 0.0705 - sparse_categorical_accuracy: 0.9765 - val_loss: 3.7973 - val_sparse_categorical_accuracy: 0.3139\n",
      "Epoch 42/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.0503 - sparse_categorical_accuracy: 0.9843 - val_loss: 3.8965 - val_sparse_categorical_accuracy: 0.3145\n",
      "Epoch 43/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9838 - val_loss: 4.0342 - val_sparse_categorical_accuracy: 0.3151\n",
      "Epoch 44/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.1014 - sparse_categorical_accuracy: 0.9660 - val_loss: 4.0766 - val_sparse_categorical_accuracy: 0.3030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.1050 - sparse_categorical_accuracy: 0.9623 - val_loss: 3.9607 - val_sparse_categorical_accuracy: 0.3237\n",
      "Epoch 46/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.0583 - sparse_categorical_accuracy: 0.9808 - val_loss: 4.0275 - val_sparse_categorical_accuracy: 0.3088\n",
      "Epoch 47/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.0440 - sparse_categorical_accuracy: 0.9854 - val_loss: 4.1076 - val_sparse_categorical_accuracy: 0.3155\n",
      "Epoch 48/128\n",
      "2048/2048 [==============================] - 54s 26ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9909 - val_loss: 4.1442 - val_sparse_categorical_accuracy: 0.3135\n",
      "Epoch 49/128\n",
      "2048/2048 [==============================] - 54s 27ms/step - loss: 0.0411 - sparse_categorical_accuracy: 0.9876 - val_loss: 4.2281 - val_sparse_categorical_accuracy: 0.3135\n",
      "Epoch 50/128\n",
      "2048/2048 [==============================] - 53s 26ms/step - loss: 0.0877 - sparse_categorical_accuracy: 0.9705 - val_loss: 4.0638 - val_sparse_categorical_accuracy: 0.3103\n",
      "Epoch 51/128\n",
      "2048/2048 [==============================] - 55s 27ms/step - loss: 0.0761 - sparse_categorical_accuracy: 0.9750 - val_loss: 4.0669 - val_sparse_categorical_accuracy: 0.3328\n",
      "Epoch 52/128\n",
      "1120/2048 [===============>..............] - ETA: 24s - loss: 0.2082 - sparse_categorical_accuracy: 0.9279"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_X[keep,:nv,:], np.expand_dims(train_Y[keep,:nv], 2), \n",
    "                  validation_data=(dev_X[:,:nv,:], np.expand_dims(dev_Y[:,:nv], 2)),\n",
    "                  epochs = 128, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(152, 8192, 4)\n"
     ]
    }
   ],
   "source": [
    "dev_Y_hat = model.predict(dev_X[:,:nv,:])\n",
    "print(dev_Y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25463542, 0.25706246, 0.23223048, 0.25607163],\n",
       "       [0.24958967, 0.26628357, 0.23360226, 0.2505245 ],\n",
       "       [0.24721539, 0.27222154, 0.22872792, 0.25183514],\n",
       "       [0.24817619, 0.2716187 , 0.24212109, 0.23808403],\n",
       "       [0.25336716, 0.2580048 , 0.238186  , 0.25044197],\n",
       "       [0.24299592, 0.26391572, 0.24205108, 0.2510373 ],\n",
       "       [0.2535667 , 0.25496587, 0.23492011, 0.2565473 ],\n",
       "       [0.2521662 , 0.2460392 , 0.23847531, 0.26331928],\n",
       "       [0.2579431 , 0.23576185, 0.23708524, 0.2692098 ],\n",
       "       [0.25768325, 0.24075094, 0.24466513, 0.25690064]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_Y_hat[6,:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EUR</th>\n",
       "      <th>EAS</th>\n",
       "      <th>SAS</th>\n",
       "      <th>AFR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>76</td>\n",
       "      <td>666</td>\n",
       "      <td>147</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EAS</th>\n",
       "      <td>94852</td>\n",
       "      <td>103971</td>\n",
       "      <td>157455</td>\n",
       "      <td>166778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAS</th>\n",
       "      <td>112119</td>\n",
       "      <td>122204</td>\n",
       "      <td>177836</td>\n",
       "      <td>151170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFR</th>\n",
       "      <td>38713</td>\n",
       "      <td>35303</td>\n",
       "      <td>41394</td>\n",
       "      <td>42359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EUR     EAS     SAS     AFR\n",
       "EUR      76     666     147     141\n",
       "EAS   94852  103971  157455  166778\n",
       "SAS  112119  122204  177836  151170\n",
       "AFR   38713   35303   41394   42359"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=confusion_matrix(dev_Y[:,:nv].astype(int).flatten(), \n",
    "                        np.argmax(dev_Y_hat[:,:nv,:], axis=-1).flatten()).T\n",
    "pd.DataFrame(result, index=[k for k,v in sorted(labels.items(), key=lambda x:x[1])], \n",
    "                     columns=[k for k,v in sorted(labels.items(), key=lambda x:x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on dev set')\n",
    "results = model.evaluate(dev_X[:,:nv,:], dev_Y[:,:nv,:], batch_size=1)\n",
    "print('dev set loss, acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take number of ancestors as Pois(2.86 * generation_time), over 1-10 (maxgen) generations\n",
    "n_fake=1000\n",
    "maxgen=10\n",
    "n_splits=2+np.hstack([ss.poisson.rvs(2.86*gen, size=n_fake//maxgen) for gen in range(1,maxgen)])\n",
    "\n",
    "# new individuals\n",
    "new_X=[]\n",
    "new_Y=[]\n",
    "for j in n_splits:\n",
    "    if j==0:\n",
    "        ind=np.random.choice(np.arange(dev_X.shape[0]), size=1)\n",
    "        new_X.append(list(dev_X[ind,:,:]))\n",
    "        new_Y.append(list(dev_Y[ind,:]))\n",
    "    # sample breakpoints uniformly\n",
    "    breaks=np.sort(V.shape[0] * ss.beta.rvs(a=1, b=1, size=j)).astype(int)\n",
    "    # pick founders uniformly at random without replacement and stitch their labels together\n",
    "    founds=np.random.choice(np.arange(dev_X.shape[0]), size=j+1, replace=False)\n",
    "    # assemble genome and labels\n",
    "    new_x,new_y = [],[]\n",
    "    new_x.append(dev_X[founds[0],:breaks[0],:])\n",
    "    new_y.append(dev_Y[founds[0],:breaks[0],:])\n",
    "    for i,found in enumerate(founds[1:-1]):\n",
    "        new_x.append(dev_X[found, breaks[i]:breaks[i+1],:])\n",
    "        new_y.append(dev_Y[found, breaks[i]:breaks[i+1],:])\n",
    "    new_x.append(dev_X[founds[-1], breaks[-1]:,:])\n",
    "    new_y.append(dev_Y[founds[-1], breaks[-1]:,:])\n",
    "    new_X.append(np.vstack(new_x))\n",
    "    new_Y.append(np.vstack(new_y))\n",
    "devv_X=np.vstack((dev_X, new_X))\n",
    "devv_Y=np.vstack((dev_Y, new_Y))\n",
    "[devv_X.shape, devv_Y.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on dev set')\n",
    "results = model.evaluate(devv_X[:,:nv,:], devv_Y[:,:nv], batch_size=1)\n",
    "print('dev set loss, acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
