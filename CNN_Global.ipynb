{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/magu/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of cores to 8\n",
    "K.set_session(K.tf.Session(config=K.tf.ConfigProto(intra_op_parallelism_threads=8, \n",
    "                                                   inter_op_parallelism_threads=8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5008, 57876, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load processed genetic data from 1000 Genomes\n",
    "chr1 = np.load('/home/magu/deepmix/data/ALL_DNA_dataset/chr1_1kg_X.npz')\n",
    "\n",
    "# create dict mapping from sampleid to superpopulation\n",
    "sample_info = pd.read_csv('/home/jsokol/Data/igsr_samples.tsv', delimiter=\"\\t\")\n",
    "sample_to_superpopulation = sample_info.set_index('Sample name')['Superpopulation code'].dropna().to_dict()\n",
    "# remove missing samples\n",
    "temp = set()\n",
    "for x in np.nditer(chr1['S']):\n",
    "    sample_id = str((x.item(0))).replace(\"'\", \"\").replace(\"b\", \"\").split(\"_\")[0]\n",
    "    if sample_id not in sample_to_superpopulation:\n",
    "        print(sample_id + ' is not in dict. Make sure to remove this sample from the dataset.')\n",
    "    elif sample_to_superpopulation[sample_id] == float('nan'):\n",
    "        print(sample_id + ' maps to nan in dict')\n",
    "        \n",
    "# define these for use, print input shape\n",
    "chr1_V = chr1['V']\n",
    "X = chr1['G']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EUR': 0, 'EAS': 1, 'AMR': 2, 'SAS': 3, 'AFR': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define number of output classes\n",
    "classes = {val:key for key,val in enumerate(set(sample_to_superpopulation.values()))}\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encode labels\n",
    "Y = np.zeros((X.shape[0], len(classes)))\n",
    "keep=set(range(X.shape[0]))\n",
    "for i in range(X.shape[0]):\n",
    "    sample_id = str(chr1['S'][i].item(0)).replace(\"'\", \"\").replace(\"b\", \"\").split(\"_\")[0]\n",
    "    Y[i, classes[sample_to_superpopulation[sample_id]]] = 1\n",
    "Y[np.array([1,353,2043]), :] # show some random samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5008, 57876, 4), (5008, 5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X.shape, Y.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle the order of the data\n",
    "randomize = np.random.choice(X.shape[0], X.shape[0], replace=False)\n",
    "X = X[randomize,:]\n",
    "Y = Y[randomize,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 57876, 4) (3000, 5)\n"
     ]
    }
   ],
   "source": [
    "# split data into training and test sets\n",
    "ntrain=3000\n",
    "X_train = X[:ntrain,:,:]\n",
    "X_test = X[ntrain:,:,:]\n",
    "Y_train = Y[:ntrain,:]\n",
    "Y_test = Y[ntrain:,:]\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_cat(shape):\n",
    "    \"\"\"\n",
    "    input_shape: The height, width and channels as a tuple.  \n",
    "        Note that this does not include the 'batch' as a dimension.\n",
    "        If you have a batch like 'X_train', \n",
    "        then you can provide the input_shape using\n",
    "        X_train.shape[1:]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n",
    "    X_input = Input(shape=shape)\n",
    "\n",
    "    # First convolutional block\n",
    "    s=64\n",
    "    X = Conv1D(filters=64, kernel_size=s ,strides=s//4, padding = 'valid', name = 'conv0')(X_input)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second convolutional block\n",
    "    X = Conv1D(64, 64, strides = 4, padding = 'same', name = 'conv1')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(Y.shape[1], activation='softmax', name='fc')(X)\n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='cnn_cat')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and compile the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 57876, 4)          0         \n",
      "_________________________________________________________________\n",
      "conv0 (Conv1D)               (None, 3614, 64)          16448     \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 3614, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3614, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 904, 64)           262208    \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 904, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 904, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 57856)             0         \n",
      "_________________________________________________________________\n",
      "fc (Dense)                   (None, 5)                 289285    \n",
      "=================================================================\n",
      "Total params: 568,453\n",
      "Trainable params: 568,197\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = cnn_cat(X_train.shape[1:])\n",
    "# compile model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# summarize model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples, validate on 2008 samples\n",
      "Epoch 1/4\n",
      "3000/3000 [==============================] - 117s 39ms/step - loss: 9.3540 - acc: 0.3737 - val_loss: 9.7775 - val_acc: 0.3929\n",
      "Epoch 2/4\n",
      "3000/3000 [==============================] - 113s 38ms/step - loss: 9.6924 - acc: 0.3987 - val_loss: 9.7768 - val_acc: 0.3934\n",
      "Epoch 3/4\n",
      "3000/3000 [==============================] - 117s 39ms/step - loss: 9.6924 - acc: 0.3987 - val_loss: 9.7768 - val_acc: 0.3934\n",
      "Epoch 4/4\n",
      " 896/3000 [=======>......................] - ETA: 1:01 - loss: 9.5341 - acc: 0.4085"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, Y_train, epochs = 4, batch_size = 128,\n",
    "                  validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'], label='train')\n",
    "plt.plot(history.history['val_acc'], label='test')\n",
    "plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(X_test, Y_test, batch_size=1)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y_hat=model.predict(X_test)\n",
    "result=confusion_matrix(np.argmax(test_Y_hat, axis=-1).flatten(), \n",
    "                        np.argmax(Y_test, axis=-1).flatten())\n",
    "pd.DataFrame(result, index=[k for k,v in sorted(classes.items(), key=lambda x:x[1])], \n",
    "                     columns=[k for k,v in sorted(classes.items(), key=lambda x:x[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
