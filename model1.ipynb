{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "rhZ0RUw8T111"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "n_snps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Matt's 'chr1_ukb_X.npz' file\n",
    "np.set_printoptions(threshold=1000)\n",
    "chr1_ukb_X = np.load('data/chr1_ukb_X.npz')\n",
    "# create dict mapping from sampleid to superpopulation\n",
    "sampleid_to_superpopulation_pandas_df = pd.read_csv('data/igsr_samples.tsv', delimiter=\"\\t\")\n",
    "sampleid_to_superpopulation_dict = sampleid_to_superpopulation_pandas_df.set_index('Sample name')['Superpopulation code'].to_dict()\n",
    "# remove samples from chr1_ukb_X that are not in dict or that do no contain value\n",
    "temp = set()\n",
    "for x in np.nditer(chr1_ukb_X['S']):\n",
    "    sample_id = str((x.item(0))).replace(\"'\", \"\").replace(\"b\", \"\").split(\"_\")[0]\n",
    "    if sample_id not in sampleid_to_superpopulation_dict:\n",
    "        print(sample_id + ' is not in dict. Make sure to remove this sample from the dataset.')\n",
    "    elif sampleid_to_superpopulation_dict[sample_id] == float('nan'):\n",
    "        print(sample_id + ' maps to nan in dict')\n",
    "# remove all SNPs from chr1_ukb_X except for the first n_snps\n",
    "chr1_ukb_X_G = chr1_ukb_X['G'][:,0:n_snps,:]\n",
    "chr1_ukb_X_V = chr1_ukb_X['V'][0:n_snps,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "# flatten input data\n",
    "X_all_data = chr1_ukb_X_G.reshape(chr1_ukb_X_G.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode labels\n",
    "Y_all_data = np.zeros((5, 5008))\n",
    "for i in range(5008):\n",
    "    sample_id = str(chr1_ukb_X['S'][i].item(0)).replace(\"'\", \"\").replace(\"b\", \"\").split(\"_\")[0]\n",
    "    if sampleid_to_superpopulation_dict[sample_id] == 'AFR':\n",
    "        Y_all_data[0,i] = 1\n",
    "    elif sampleid_to_superpopulation_dict[sample_id] == 'AMR':\n",
    "        Y_all_data[1,i] = 1\n",
    "    elif sampleid_to_superpopulation_dict[sample_id] == 'EAS':\n",
    "        Y_all_data[2,i] = 1\n",
    "    elif sampleid_to_superpopulation_dict[sample_id] == 'EUR':\n",
    "        Y_all_data[3,i] = 1\n",
    "    elif sampleid_to_superpopulation_dict[sample_id] == 'SAS':\n",
    "        Y_all_data[4,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly shuffle the order of the data\n",
    "randomize = np.arange(X_all_data.shape[1])\n",
    "np.random.shuffle(randomize)\n",
    "X_all_data = X_all_data[:,randomize]\n",
    "Y_all_data = Y_all_data[:,randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and test sets\n",
    "X_train = X_all_data[:,:4000]\n",
    "X_test = X_all_data[:,4000:]\n",
    "Y_train = Y_all_data[:,:4000]\n",
    "Y_test = Y_all_data[:,4000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fcAcBRAAT12q"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"tf.float32\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"tf.float32\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape = [n_x, None], name = 'X')\n",
    "    Y = tf.placeholder(tf.float32, shape = [n_y, None], name = 'Y')\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gPi-SeuWT12u"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [n_snps,n_snps*4], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [n_snps,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [30,n_snps], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [30,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [5,30], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [5,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nC7CYNk0T120"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1,X), b1)                       # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2,A1), b2)                      # Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3,A2), b3)                      # Z3 = np.dot(W3, A2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1_bzQXSJT125"
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost \n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "siFLpYfkT12_"
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AISfljZVT13B",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.758662\n",
      "Cost after epoch 100: 0.050831\n",
      "Cost after epoch 200: 0.010944\n",
      "Cost after epoch 300: 0.008708\n",
      "Cost after epoch 400: 0.012894\n",
      "Cost after epoch 500: 0.007452\n",
      "Cost after epoch 600: 0.006564\n",
      "Cost after epoch 700: 0.003298\n",
      "Cost after epoch 800: 0.003270\n",
      "Cost after epoch 900: 0.003678\n",
      "Cost after epoch 1000: 0.002979\n",
      "Cost after epoch 1100: 0.003295\n",
      "Cost after epoch 1200: 0.002603\n",
      "Cost after epoch 1300: 0.002366\n",
      "Cost after epoch 1400: 0.002342\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.99975\n",
      "Test Accuracy: 0.82738096\n"
     ]
    }
   ],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "BFd89",
   "launcher_item_id": "AH2rK"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
